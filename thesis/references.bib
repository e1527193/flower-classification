@article{an2019,
  title = {Identification and {{Classification}} of {{Maize Drought Stress Using Deep Convolutional Neural Network}}},
  author = {An, Jiangyong and Li, Wanyi and Li, Maosong and Cui, Sanrong and Yue, Huanran},
  date = {2019-02},
  journaltitle = {Symmetry},
  volume = {11},
  number = {2},
  pages = {256},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-8994},
  doi = {10.3390/sym11020256},
  keywords = {deep convolutional neural network,drought classification,drought identification,drought stress,maize,phenotype,traditional machine learning},
  file = {/home/zenon/Zotero/storage/GUCGV95A/An et al. - 2019 - Identification and Classification of Maize Drought.pdf}
}

@article{ariss2022,
  title = {{{ResNet-based Parkinson}}'s {{Disease Classification}}},
  author = {Ariss, Omar El and Hu, Kaoning},
  date = {2022},
  journaltitle = {IEEE Transactions on Artificial Intelligence},
  pages = {1--11},
  issn = {2691-4581},
  doi = {10.1109/TAI.2022.3193651},
  eventtitle = {{{IEEE Transactions}} on {{Artificial Intelligence}}},
  keywords = {Convolutional Neural Networks,deep learning,Deep learning,diagnosis,Diseases,Feature extraction,frequency features,heat map,Heating systems,Parkinson's disease,Parkinson's Disease,Recording,Residual neural networks,ResNet,speech recording,transfer learning}
}

@article{atanasov2021,
  title = {Predicting {{Soil Moisture Based}} on the {{Color}} of the {{Leaves Using Data Mining}} and {{Machine Learning Techniques}}},
  author = {Atanasov, S. S.},
  date = {2021-01},
  journaltitle = {IOP Conference Series: Materials Science and Engineering},
  shortjournal = {IOP Conf. Ser.: Mater. Sci. Eng.},
  volume = {1031},
  number = {1},
  pages = {012076},
  publisher = {{IOP Publishing}},
  issn = {1757-899X},
  doi = {10.1088/1757-899X/1031/1/012076},
  file = {/home/zenon/Zotero/storage/TIZ9KQTP/Atanasov - 2021 - Predicting Soil Moisture Based on the Color of the.pdf}
}

@article{awad2019,
  title = {Toward {{Precision}} in {{Crop Yield Estimation Using Remote Sensing}} and {{Optimization Techniques}}},
  author = {Awad, Mohamad M.},
  date = {2019-03},
  journaltitle = {Agriculture},
  volume = {9},
  number = {3},
  pages = {54},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2077-0472},
  doi = {10.3390/agriculture9030054},
  keywords = {crop yield,environment,evapotranspiration,image processing,remote sensing},
  file = {/home/zenon/Zotero/storage/C65MLVQW/Awad - 2019 - Toward Precision in Crop Yield Estimation Using Re.pdf}
}

@inproceedings{azimi2020,
  title = {Water {{Stress Identification}} in {{Chickpea Plant Shoot Images Using Deep Learning}}},
  booktitle = {2020 {{IEEE}} 17th {{India Council International Conference}} ({{INDICON}})},
  author = {Azimi, Shiva and Kaur, Taranjit and Gandhi, Tapan K},
  date = {2020-12},
  pages = {1--7},
  issn = {2325-9418},
  doi = {10.1109/INDICON49873.2020.9342388},
  eventtitle = {2020 {{IEEE}} 17th {{India Council International Conference}} ({{INDICON}})},
  keywords = {computer vision,deep learning,Deep learning,Nitrogen,plant phenotyping,Proteins,Real-time systems,Stress,Support vector machines,Tools,water stress}
}

@article{azimi2021,
  title = {Intelligent {{Monitoring}} of {{Stress Induced}} by {{Water Deficiency}} in {{Plants Using Deep Learning}}},
  author = {Azimi, Shiva and Wadhawan, Rohan and Gandhi, Tapan K.},
  date = {2021},
  journaltitle = {IEEE Transactions on Instrumentation and Measurement},
  volume = {70},
  pages = {1--13},
  issn = {1557-9662},
  doi = {10.1109/TIM.2021.3111994},
  eventtitle = {{{IEEE Transactions}} on {{Instrumentation}} and {{Measurement}}},
  keywords = {Computer vision,convolutional neural network (CNN),Convolutional neural networks,Crops,deep learning (DL),Long short term memory,long short-term memory (LSTM),monitoring,neural network,Pipelines,plant phenotyping,spatiotemporal analysis,Stress,Visualization,water stress},
  file = {/home/zenon/Zotero/storage/RSNWFVIZ/Azimi et al. - 2021 - Intelligent Monitoring of Stress Induced by Water .pdf}
}

@article{benos2021,
  title = {Machine {{Learning}} in {{Agriculture}}: {{A Comprehensive Updated Review}}},
  shorttitle = {Machine {{Learning}} in {{Agriculture}}},
  author = {Benos, Lefteris and Tagarakis, Aristotelis C. and Dolias, Georgios and Berruto, Remigio and Kateris, Dimitrios and Bochtis, Dionysis},
  date = {2021-01},
  journaltitle = {Sensors},
  volume = {21},
  number = {11},
  pages = {3758},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s21113758},
  keywords = {artificial intelligence,crop management,livestock management,machine learning,precision agriculture,precision livestock farming,soil management,water management},
  file = {/home/zenon/Zotero/storage/ILXR97E5/Benos et al. - 2021 - Machine Learning in Agriculture A Comprehensive U.pdf}
}

@article{bergstra2012,
  title = {Random {{Search}} for {{Hyper-Parameter Optimization}}},
  author = {Bergstra, James and Bengio, Yoshua},
  date = {2012-02-01},
  journaltitle = {The Journal of Machine Learning Research},
  shortjournal = {J. Mach. Learn. Res.},
  volume = {13},
  pages = {281--305},
  issn = {1532-4435},
  issue = {null},
  keywords = {deep learning,global optimization,model selection,neural networks,response surface modeling}
}

@online{bochkovskiy2020,
  title = {{{YOLOv4}}: {{Optimal Speed}} and {{Accuracy}} of {{Object Detection}}},
  shorttitle = {{{YOLOv4}}},
  author = {Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  date = {2020-04-22},
  eprint = {2004.10934},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2004.10934},
  issue = {arXiv:2004.10934},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/zenon/Zotero/storage/RELLHNCA/Bochkovskiy et al. - 2020 - YOLOv4 Optimal Speed and Accuracy of Object Detec.pdf}
}

@online{brown2020,
  title = {Language {{Models Are Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2005.14165},
  issue = {arXiv:2005.14165},
  keywords = {Computer Science - Computation and Language},
  file = {/home/zenon/Zotero/storage/56LE395G/Brown et al. - 2020 - Language Models Are Few-Shot Learners.pdf}
}

@article{chandel2021,
  title = {Identifying {{Crop Water Stress Using Deep Learning Models}}},
  author = {Chandel, Narendra Singh and Chakraborty, Subir Kumar and Rajwade, Yogesh Anand and Dubey, Kumkum and Tiwari, Mukesh K. and Jat, Dilip},
  date = {2021-05-01},
  journaltitle = {Neural Computing and Applications},
  shortjournal = {Neural Comput \& Applic},
  volume = {33},
  number = {10},
  pages = {5353--5367},
  issn = {1433-3058},
  doi = {10.1007/s00521-020-05325-4},
  keywords = {Confusion matrix,Crop phenotyping,DCNN,Digital agriculture,Machine learning}
}

@article{davis1992,
  title = {Operational Prototyping: A New Development Approach},
  shorttitle = {Operational Prototyping},
  author = {Davis, A.M.},
  date = {1992-09},
  journaltitle = {IEEE Software},
  volume = {9},
  number = {5},
  pages = {70--78},
  issn = {1937-4194},
  doi = {10.1109/52.156899},
  abstract = {The two traditional types of software prototyping methods, throwaway prototyping and evolutionary prototyping, are compared, and prototyping's relation to conventional software development is discussed. Operational prototyping, a method that combines throwaway and evolutionary prototyping techniques by layering a rapid prototype over a solid evolutionary base, is described. Operational prototyping's implications for configuration management, quality assurance, and general project management are reviewed. The application of operational prototyping to a prototype ocean surveillance terminal is presented.{$<>$}},
  eventtitle = {{{IEEE Software}}},
  keywords = {Application software,Oceans,Programming,Project management,Prototypes,Quality assurance,Quality management,Software prototyping,Solids,Surveillance},
  file = {/home/zenon/Zotero/storage/7NBJW3VE/Davis - 1992 - Operational prototyping a new development approac.pdf;/home/zenon/Zotero/storage/N96N3CIA/156899.html}
}

@inproceedings{deng2009,
  title = {{{ImageNet}}: {{A Large-Scale Hierarchical Image Database}}},
  shorttitle = {{{ImageNet}}},
  booktitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  date = {2009-06},
  pages = {248--255},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2009.5206848},
  eventtitle = {2009 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {Explosions,Image databases,Image retrieval,Information retrieval,Internet,Large-scale systems,Multimedia databases,Ontologies,Robustness,Spine}
}

@article{everingham2010,
  title = {The {{Pascal Visual Object Classes}} ({{VOC}}) {{Challenge}}},
  author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
  date = {2010-06-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {88},
  number = {2},
  pages = {303--338},
  issn = {1573-1405},
  doi = {10.1007/s11263-009-0275-4},
  urldate = {2023-09-07},
  abstract = {The Pascal Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing the vision and machine learning communities with a standard dataset of images and annotation, and standard evaluation procedures. Organised annually from 2005 to present, the challenge and its associated dataset has become accepted as the benchmark for object detection.},
  langid = {english},
  keywords = {Benchmark,Database,Object detection,Object recognition},
  file = {/home/zenon/Zotero/storage/FCRT6NYG/Everingham et al. - 2010 - The Pascal Visual Object Classes (VOC) Challenge.pdf}
}

@inproceedings{he2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016-06},
  pages = {770--778},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.90},
  eventtitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  keywords = {Complexity theory,Degradation,Image recognition,Image segmentation,Neural networks,Training,Visualization},
  file = {/home/zenon/Zotero/storage/JDX3S8QK/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf}
}

@software{jocher2022,
  title = {Ultralytics/{{Yolov5}}: {{V7}}.0 - {{YOLOv5 SOTA Realtime Instance Segmentation}}},
  shorttitle = {Ultralytics/{{Yolov5}}},
  author = {Jocher, Glenn and Chaurasia, Ayush and Stoken, Alex and Borovec, Jirka and {NanoCode012} and Kwon, Yonghye and Michael, Kalen and {TaoXie} and Fang, Jiacong and {imyhxy} and {Lorna} and Yifu, Zeng and Wong, Colin and V, Abhiram and Montes, Diego and Wang, Zhiqiang and Fati, Cristi and Nadar, Jebastin and {Laughing} and {UnglvKitDe} and Sonck, Victor and {tkianai} and {yxNONG} and Skalski, Piotr and Hogan, Adam and Nair, Dhruv and Strobel, Max and Jain, Mrinal},
  date = {2022-11-22},
  doi = {10.5281/zenodo.7347926},
  organization = {{Zenodo}}
}

@online{kingma2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  date = {2017-01-29},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1412.6980},
  issue = {arXiv:1412.6980},
  keywords = {Computer Science - Machine Learning},
  file = {/home/zenon/Zotero/storage/DQAJEA4B/Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf}
}

@article{krosney2023,
  title = {Inside {{Out}}: {{Transforming Images}} of {{Lab-Grown Plants}} for {{Machine Learning Applications}} in {{Agriculture}}},
  shorttitle = {Inside {{Out}}},
  author = {Krosney, A. E. and Sotoodeh, P. and Henry, C. J. and Beck, M. A. and Bidinosti, C. P.},
  date = {2023-07-06},
  journaltitle = {Frontiers in Artificial Intelligence},
  shortjournal = {Front. Artif. Intell.},
  volume = {6},
  eprint = {2211.02972},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {1200977},
  issn = {2624-8212},
  doi = {10.3389/frai.2023.1200977},
  urldate = {2023-08-25},
  abstract = {Machine learning tasks often require a significant amount of training data for the resultant network to perform suitably for a given problem in any domain. In agriculture, dataset sizes are further limited by phenotypical differences between two plants of the same genotype, often as a result of differing growing conditions. Synthetically-augmented datasets have shown promise in improving existing models when real data is not available. In this paper, we employ a contrastive unpaired translation (CUT) generative adversarial network (GAN) and simple image processing techniques to translate indoor plant images to appear as field images. While we train our network to translate an image containing only a single plant, we show that our method is easily extendable to produce multiple-plant field images. Furthermore, we use our synthetic multi-plant images to train several YoloV5 nano object detection models to perform the task of plant detection and measure the accuracy of the model on real field data images. Including training data generated by the CUT-GAN leads to better plant detection performance compared to a network trained solely on real data.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/zenon/Zotero/storage/Y5MUHPDE/Krosney et al. - 2023 - Inside Out Transforming Images of Lab-Grown Plant.pdf;/home/zenon/Zotero/storage/8NB5H9E8/2211.html}
}

@article{kuznetsova2020,
  title = {The {{Open Images Dataset V4}}: {{Unified Image Classification}}, {{Object Detection}}, and {{Visual Relationship Detection}} at {{Scale}}},
  shorttitle = {The {{Open Images Dataset V4}}},
  author = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and Duerig, Tom and Ferrari, Vittorio},
  date = {2020-07},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {128},
  number = {7},
  eprint = {1811.00982},
  eprinttype = {arxiv},
  pages = {1956--1981},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-020-01316-z},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/R6SKDLQU/Kuznetsova et al. - 2020 - The Open Images Dataset V4 Unified Image Classifi.pdf}
}

@online{lin2015,
  title = {Microsoft {{COCO}}: {{Common Objects}} in {{Context}}},
  shorttitle = {Microsoft {{COCO}}},
  author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
  date = {2015-02-20},
  eprint = {1405.0312},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1405.0312},
  issue = {arXiv:1405.0312},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/ZMCI6A8T/Lin et al. - 2015 - Microsoft COCO Common Objects in Context.pdf}
}

@incollection{liu2016,
  title = {{{SSD}}: {{Single Shot MultiBox Detector}}},
  shorttitle = {{{SSD}}},
  author = {Liu, Wei and Anguelov, Dragomir and Erhan, Dumitru and Szegedy, Christian and Reed, Scott and Fu, Cheng-Yang and Berg, Alexander C.},
  date = {2016},
  volume = {9905},
  eprint = {1512.02325},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {21--37},
  doi = {10.1007/978-3-319-46448-0_2},
  urldate = {2023-08-24},
  abstract = {We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. Our SSD model is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stage and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component. Experimental results on the PASCAL VOC, MS COCO, and ILSVRC datasets confirm that SSD has comparable accuracy to methods that utilize an additional object proposal step and is much faster, while providing a unified framework for both training and inference. Compared to other single stage methods, SSD has much better accuracy, even with a smaller input image size. For \$300\textbackslash times 300\$ input, SSD achieves 72.1\% mAP on VOC2007 test at 58 FPS on a Nvidia Titan X and for \$500\textbackslash times 500\$ input, SSD achieves 75.1\% mAP, outperforming a comparable state of the art Faster R-CNN model. Code is available at https://github.com/weiliu89/caffe/tree/ssd .},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/JQWR9QIY/Liu et al. - 2016 - SSD Single Shot MultiBox Detector.pdf;/home/zenon/Zotero/storage/Y8UXAEEU/1512.html}
}

@article{lopez-garcia2022,
  title = {Machine {{Learning-Based Processing}} of {{Multispectral}} and {{RGB UAV Imagery}} for the {{Multitemporal Monitoring}} of {{Vineyard Water Status}}},
  author = {López-García, Patricia and Intrigliolo, Diego and Moreno, Miguel A. and Martínez-Moreno, Alejandro and Ortega, José Fernando and Pérez-Álvarez, Eva Pilar and Ballesteros, Rocío},
  date = {2022-09},
  journaltitle = {Agronomy},
  volume = {12},
  number = {9},
  pages = {2122},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-4395},
  doi = {10.3390/agronomy12092122},
  keywords = {ANN,machine learning,multispectral images,RGB images,UAV,vineyard,water stress},
  file = {/home/zenon/Zotero/storage/MJSM2BFH/López-García et al. - 2022 - Machine Learning-Based Processing of Multispectral.pdf}
}

@article{mateo-aroca2019,
  title = {Remote {{Image Capture System}} to {{Improve Aerial Supervision}} for {{Precision Irrigation}} in {{Agriculture}}},
  author = {Mateo-Aroca, Antonio and García-Mateos, Ginés and Ruiz-Canales, Antonio and Molina-García-Pardo, José María and Molina-Martínez, José Miguel},
  date = {2019-02},
  journaltitle = {Water},
  volume = {11},
  number = {2},
  pages = {255},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2073-4441},
  doi = {10.3390/w11020255},
  keywords = {image capture system,irrigation management,lettuce,wireless,ZigBee and XBee},
  file = {/home/zenon/Zotero/storage/3JZLQNJT/Mateo-Aroca et al. - 2019 - Remote Image Capture System to Improve Aerial Supe.pdf}
}

@article{mcenroe2022,
  title = {A {{Survey}} on the {{Convergence}} of {{Edge Computing}} and {{AI}} for {{UAVs}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {A {{Survey}} on the {{Convergence}} of {{Edge Computing}} and {{AI}} for {{UAVs}}},
  author = {McEnroe, Patrick and Wang, Shen and Liyanage, Madhusanka},
  date = {2022-09},
  journaltitle = {IEEE Internet of Things Journal},
  volume = {9},
  number = {17},
  pages = {15435--15459},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2022.3176400},
  eventtitle = {{{IEEE Internet}} of {{Things Journal}}},
  keywords = {Artificial intelligence,Artificial intelligence (AI),Autonomous aerial vehicles,Cloud computing,edge AI,edge computing,Edge computing,edge intelligence,Internet of Things,Internet of Things (IoT),MEC,Servers,Task analysis,unmanned aerial vehicle (UAV)},
  file = {/home/zenon/Zotero/storage/3ECY7VJ5/McEnroe et al. - 2022 - A Survey on the Convergence of Edge Computing and .pdf}
}

@article{nadafzadeh2019,
  title = {Design and {{Fabrication}} of an {{Intelligent Control System}} for {{Determination}} of {{Watering Time}} for {{Turfgrass Plant Using Computer Vision System}} and {{Artificial Neural Network}}},
  author = {Nadafzadeh, Maryam and Abdanan Mehdizadeh, Saman},
  date = {2019-10-01},
  journaltitle = {Precision Agriculture},
  shortjournal = {Precision Agric},
  volume = {20},
  number = {5},
  pages = {857--879},
  issn = {1573-1618},
  doi = {10.1007/s11119-018-9618-x},
  keywords = {Artificial neural network,Digital image processing,Drought stress,Genetic algorithm,Intelligent irrigation control}
}

@article{ramos-giraldo2020,
  title = {Drought {{Stress Detection Using Low-Cost Computer Vision Systems}} and {{Machine Learning Techniques}}},
  author = {Ramos-Giraldo, Paula and Reberg-Horton, Chris and Locke, Anna M. and Mirsky, Steven and Lobaton, Edgar},
  date = {2020-05},
  journaltitle = {IT Professional},
  volume = {22},
  number = {3},
  pages = {27--29},
  issn = {1941-045X},
  doi = {10.1109/MITP.2020.2986103},
  eventtitle = {{{IT Professional}}},
  keywords = {Agriculture,Climate change,Computer vision,Loss measurement,Machine learning,Stress measurement}
}

@inproceedings{ramos-giraldo2020a,
  title = {Low-{{Cost Smart Camera System}} for {{Water Stress Detection}} in {{Crops}}},
  booktitle = {2020 {{IEEE SENSORS}}},
  author = {Ramos-Giraldo, Paula and Reberg-Horton, S. Chris and Mirsky, Steven and Lobaton, Edgar and Locke, Anna M. and Henriquez, Esleyther and Zuniga, Ane and Minin, Artem},
  date = {2020-10},
  pages = {1--4},
  issn = {2168-9229},
  doi = {10.1109/SENSORS47125.2020.9278744},
  eventtitle = {2020 {{IEEE SENSORS}}},
  keywords = {Agriculture,Cameras,Computational modeling,computer vision,edge and cloud computing,IoT,machine learning,Sensor systems,Sensors,smart farming,Stress,Temperature sensors}
}

@article{rico-chavez2022,
  title = {Machine {{Learning}} for {{Plant Stress Modeling}}: {{A Perspective}} towards {{Hormesis Management}}},
  shorttitle = {Machine {{Learning}} for {{Plant Stress Modeling}}},
  author = {Rico-Chávez, Amanda Kim and Franco, Jesus Alejandro and Fernandez-Jaramillo, Arturo Alfonso and Contreras-Medina, Luis Miguel and Guevara-González, Ramón Gerardo and Hernandez-Escobedo, Quetzalcoatl},
  date = {2022-04-02},
  journaltitle = {Plants},
  shortjournal = {Plants (Basel)},
  volume = {11},
  number = {7},
  eprint = {35406950},
  eprinttype = {pmid},
  pages = {970},
  issn = {2223-7747},
  doi = {10.3390/plants11070970},
  urldate = {2023-08-25},
  abstract = {Plant stress is one of the most significant factors affecting plant fitness and, consequently, food production. However, plant stress may also be profitable since it behaves hormetically; at low doses, it stimulates positive traits in crops, such as the synthesis of specialized metabolites and additional stress tolerance. The controlled exposure of crops to low doses of stressors is therefore called hormesis management, and it is a promising method to increase crop productivity and quality. Nevertheless, hormesis management has severe limitations derived from the complexity of plant physiological responses to stress. Many technological advances assist plant stress science in overcoming such limitations, which results in extensive datasets originating from the multiple layers of the plant defensive response. For that reason, artificial intelligence tools, particularly Machine Learning (ML) and Deep Learning (DL), have become crucial for processing and interpreting data to accurately model plant stress responses such as genomic variation, gene and protein expression, and metabolite biosynthesis. In this review, we discuss the most recent ML and DL applications in plant stress science, focusing on their potential for improving the development of hormesis management protocols.},
  pmcid = {PMC9003083},
  file = {/home/zenon/Zotero/storage/56I7ELHW/Rico-Chávez et al. - 2022 - Machine Learning for Plant Stress Modeling A Pers.pdf}
}

@inproceedings{sears2007,
  title = {Prototyping {{Tools}} and {{Techniques}}},
  booktitle = {The {{Human-Computer Interaction Handbook}}},
  editor = {Sears, Andrew and Jacko, Julie A. and Jacko, Julie A.},
  date = {2007-09-19},
  pages = {1043--1066},
  publisher = {{CRC Press}},
  doi = {10.1201/9781410615862-66},
  urldate = {2023-09-17},
  abstract = {We begin with our definition of a prototype and then discuss prototypes as design artifacts, introducing four dimensions for analyzing them. We then discuss the role of prototyping within the design process, in particular the concept of a design space, and how it is expanded and contracted by generating and selecting design ideas. The next three sections describe specific prototyping approaches: Rapid prototyping, both off-line and on-line, for early stages of design, iterative prototyping, which uses on-line development tools, and evolutionary prototyping, which must be based on a sound software architecture.},
  isbn = {978-0-429-16397-5},
  langid = {english}
}

@article{selvaraju2020,
  title = {Grad-{{CAM}}: {{Visual Explanations}} from {{Deep Networks}} via {{Gradient-based Localization}}},
  shorttitle = {Grad-{{CAM}}},
  author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  date = {2020-02},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {128},
  number = {2},
  eprint = {1610.02391},
  eprinttype = {arxiv},
  pages = {336--359},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-019-01228-7},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/zenon/Zotero/storage/QC22JBMX/Selvaraju et al. - 2020 - Grad-CAM Visual Explanations from Deep Networks v.pdf}
}

@article{su2020,
  title = {Machine {{Learning-Based Crop Drought Mapping System}} by {{UAV Remote Sensing RGB Imagery}}},
  author = {Su, Jinya and Coombes, Matthew and Liu, Cunjia and Zhu, Yongchao and Song, Xingyang and Fang, Shibo and Guo, Lei and Chen, Wen-Hua},
  date = {2020-01},
  journaltitle = {Unmanned Systems},
  shortjournal = {Un. Sys.},
  volume = {08},
  number = {01},
  pages = {71--83},
  publisher = {{World Scientific Publishing Co.}},
  issn = {2301-3850},
  doi = {10.1142/S2301385020500053},
  keywords = {Area-wise classification,Support Vector Machine (SVM),Unmanned Aerial Vehicle (UAV),wheat drought mapping},
  file = {/home/zenon/Zotero/storage/KUHDEQJF/Su et al. - 2020 - Machine Learning-Based Crop Drought Mapping System.pdf}
}

@article{virnodkar2020,
  title = {Remote {{Sensing}} and {{Machine Learning}} for {{Crop Water Stress Determination}} in {{Various Crops}}: {{A Critical Review}}},
  shorttitle = {Remote {{Sensing}} and {{Machine Learning}} for {{Crop Water Stress Determination}} in {{Various Crops}}},
  author = {Virnodkar, Shyamal S. and Pachghare, Vinod K. and Patil, V. C. and Jha, Sunil Kumar},
  date = {2020-10-01},
  journaltitle = {Precision Agriculture},
  shortjournal = {Precision Agric},
  volume = {21},
  number = {5},
  pages = {1121--1155},
  issn = {1573-1618},
  doi = {10.1007/s11119-020-09711-9},
  keywords = {Crop water stress,Crops,Machine learning,Remote sensing}
}

@article{wakamori2020,
  title = {Multimodal {{Neural Network}} with {{Clustering-Based Drop}} for {{Estimating Plant Water Stress}}},
  author = {Wakamori, Kazumasa and Mizuno, Ryosuke and Nakanishi, Gota and Mineno, Hiroshi},
  date = {2020-01-01},
  journaltitle = {Computers and Electronics in Agriculture},
  shortjournal = {Computers and Electronics in Agriculture},
  volume = {168},
  pages = {105118},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2019.105118},
  keywords = {Image processing,Multimodal deep learning,Plant water stress,Time-series modeling}
}

@online{wang2022,
  title = {{{YOLOv7}}: {{Trainable Bag-of-Freebies Sets New State-of-the-Art}} for {{Real-Time Object Detectors}}},
  shorttitle = {{{YOLOv7}}},
  author = {Wang, Chien-Yao and Bochkovskiy, Alexey and Liao, Hong-Yuan Mark},
  date = {2022-07-06},
  eprint = {2207.02696},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.2207.02696},
  issue = {arXiv:2207.02696},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/G27M4VFA/Wang et al. - 2022 - YOLOv7 Trainable Bag-of-Freebies Sets New State-o.pdf}
}

@online{zheng2019,
  title = {Distance-{{IoU Loss}}: {{Faster}} and {{Better Learning}} for {{Bounding Box Regression}}},
  shorttitle = {Distance-{{IoU Loss}}},
  author = {Zheng, Zhaohui and Wang, Ping and Liu, Wei and Li, Jinze and Ye, Rongguang and Ren, Dongwei},
  date = {2019-11-19},
  eprint = {1911.08287},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1911.08287},
  issue = {arXiv:1911.08287},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/A7KFIFE2/Zheng et al. - 2019 - Distance-IoU Loss Faster and Better Learning for .pdf}
}

@article{zhong2022,
  title = {Classification of {{Cassava Leaf Disease Based}} on a {{Non-Balanced Dataset Using Transformer-Embedded ResNet}}},
  author = {Zhong, Yiwei and Huang, Baojin and Tang, Chaowei},
  date = {2022-09},
  journaltitle = {Agriculture},
  volume = {12},
  number = {9},
  pages = {1360},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2077-0472},
  doi = {10.3390/agriculture12091360},
  keywords = {cassava diseases,convolutional neural network,focal angular margin penalty softmax loss (FAMP-Softmax),intelligent agricultural engineering,transformer-embedded ResNet (T-RNet),unbalanced image samples},
  file = {/home/zenon/Zotero/storage/P7652AHL/Zhong et al. - 2022 - Classification of Cassava Leaf Disease Based on a .pdf}
}

@online{zhou2015,
  title = {Learning {{Deep Features}} for {{Discriminative Localization}}},
  author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
  date = {2015-12-13},
  eprint = {1512.04150},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1512.04150},
  issue = {arXiv:1512.04150},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/zenon/Zotero/storage/VMLHUG7J/Zhou et al. - 2015 - Learning Deep Features for Discriminative Localiza.pdf}
}

@article{zhuang2017,
  title = {Early {{Detection}} of {{Water Stress}} in {{Maize Based}} on {{Digital Images}}},
  author = {Zhuang, Shuo and Wang, Ping and Jiang, Boran and Li, Maosong and Gong, Zhihong},
  date = {2017-08-01},
  journaltitle = {Computers and Electronics in Agriculture},
  shortjournal = {Computers and Electronics in Agriculture},
  volume = {140},
  pages = {461--468},
  issn = {0168-1699},
  doi = {10.1016/j.compag.2017.06.022},
  keywords = {Early maize,Feature extraction,Gradient boosting decision tree,Image segmentation,Water stress}
}
